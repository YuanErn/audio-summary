{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNkd4QGeSiK9clkJAoKuhx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuanErn/audio-summary/blob/main/audiosummary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzxGDzA1o8IQ",
        "outputId": "c736a346-e552-48ca-b82a-818375cef4e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7g-mjsPpAY_",
        "outputId": "51def4fb-f673-4b7c-cec6-02864d206b55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-whisper\n",
            "  Using cached openai-whisper-20230314.tar.gz (792 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (9.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (1.13.1+cu116)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (4.65.0)\n",
            "Collecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (3.10.7)\n",
            "Collecting lit\n",
            "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796926 sha256=8c338730728c21264174d65462073ac9816c20ea3567d6a5e4a8652ff78412bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/85/e6/0bb9507b8e4f3f6d9c6dcf318bc3514739430375aa8e9eaf5b\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=90368219f76797bf14b9713dc52e17eb5264e644aaca335addd57265f8f10111\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, ffmpeg-python, triton, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 lit-16.0.0 openai-whisper-20230314 tiktoken-0.3.1 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BHo_1Ahmc6O2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d4867b-4464-4c8b-99c7-628bc3c3ccdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:18<00:00, 166MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discussed and decisions made.\n",
            "\n",
            "Meeting Minutes:\n",
            "\n",
            "Meeting Purpose: Trial Balance Dashboard Review Session\n",
            "\n",
            "Date: [Insert Date]\n",
            "\n",
            "Attendees: [Insert Names]\n",
            "\n",
            "Agenda:\n",
            "\n",
            "1. Review of Trial Balance Dashboard\n",
            "2. Dashboard Features and Functionality\n",
            "3. Action Points and Next Steps\n",
            "\n",
            "Discussion:\n",
            "\n",
            "- The meeting commenced with the client expressing satisfaction with the dashboard's overall look and feel, but raised some concerns about certain features \n",
            "- The developer revisited the dashboard with the client and walked them through the various features, including the drill-down functionality, trend analysis charts, and the filters \n",
            "- The client asked about the ability to modify some of these features to better serve their unique business needs, and the developer agreed that customizations could be made \n",
            "- The client raised a concern about the accuracy of some of the data on the dashboard, and the developer confirmed that there was a bug in the system that was causing some discrepancies. The developer promised to fix the issue before the next meeting \n",
            "- The developer also provided a timeline for testing and implementation of the customizations, and agreed to keep the client updated throughout the process \n",
            "- The meeting ended with an agreement on the next steps, including scheduling a follow-up meeting to review the changes and evaluate the dashboard's overall effectiveness. \n",
            "\n",
            "Action Points:\n",
            "\n",
            "- Developer to fix the bug causing data discrepancies on the dashboard before the next meeting \n",
            "- Client to provide additional feedback on necessary customizations \n",
            "- Developer to provide regular updates on progress towards implementing the customizations \n",
            "- Schedule a follow-up meeting to review the changes made and evaluate the dashboard's overall effectiveness \n",
            "\n",
            "Conclusion:\n",
            "\n",
            "Overall, the meeting was successful in addressing the client's concerns and establishing a clear plan of action for improving the trial balance dashboard. Both parties expressed satisfaction with the outcome of the meeting, and are looking forward to the improvements that will be made to the dashboard in the coming weeks.\n",
            "Completed in 00:01:46\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import json\n",
        "import openai\n",
        "import time\n",
        "\n",
        "# Timing the program\n",
        "startTime = time.time()\n",
        "\n",
        "# API Key from OpenAI\n",
        "secret_file = open(\"API.txt\", \"r\")\n",
        "openai.api_key = secret_file.readline()\n",
        "secret_file.close()\n",
        "\n",
        "whisperModel = whisper.load_model(\"large-v1\")\n",
        "whisperAudio = whisper.load_audio(\"testing2.mp4\")# Name of the file here\n",
        "\n",
        "# This moves the audio to the same device as the model (cuda if enabled)\n",
        "mel = whisper.log_mel_spectrogram(whisperAudio).to(whisperModel.device)\n",
        "\n",
        "whisperResult = str(whisperModel.transcribe(whisperAudio, language = \"Chinese\"))# Specify language when possible\n",
        "\n",
        "# Context for the data. This will be passed on to ChatGPT\n",
        "audioTopic = \"a meeting session for trial balance dashboard review session\" # What was the audio about?\n",
        "partiesInvolved = \"developer and client\" # To whom did the voices in the audio belong to?\n",
        "actionToDo = \"summarize this meeting into meeting minutes. Point form with great details into the topics\" # What do u want to be done with this information\n",
        "prompt = \"This is \" + audioTopic + \" between \" + partiesInvolved + \".\" + actionToDo\n",
        "\n",
        "# Settings for the model\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\", \n",
        "    messages=[{\"role\":\"user\", \"content\": prompt}]\n",
        ")\n",
        "\n",
        "# Print the generated text\n",
        "preTransform = str(response.choices[0])\n",
        "postTransform = json.loads(preTransform)\n",
        "answer = postTransform[\"message\"][\"content\"]\n",
        "\n",
        "print (answer)\n",
        "print (\"Completed in\", time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - startTime)))\n"
      ]
    }
  ]
}